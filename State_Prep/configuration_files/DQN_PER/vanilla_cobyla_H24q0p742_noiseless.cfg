[general]
episodes = 10000

[env]
num_qubits = 4
num_layers = 40
err_mitig = 0
rand_halt = 0

n_shots = 0
noise_models = 0
noise_values = 0

fn_type = incremental_with_fixed_ends
thresholds = [1.6e-3]
accept_err = 1.6e-3
switch_episodes = [100000]
curriculum_type = VanillaCurriculum

[problem]
ham_type = H2
geometry = H .0 .0 .0; H .0 .0 0.742
taper = 1
mapping = jordan_wigner

[agent]
batch_size = 1000
memory_size = 20000
neurons = [1000,1000,1000,1000,1000]
dropout = 0.
learning_rate = 0.0003
angles = 0
en_state = 1
agent_type = DQN_PER
agent_class = DQN_PER
init_net = 0

update_target_net = 500
final_gamma = 0.005
epsilon_decay = 0.99995
epsilon_min = 0.05
epsilon_restart = 1.0
alpha=0.6
beta_init= 0.4
beta_increment= 0.001
beta_max= 1.0
memory_reset_switch= 5
memory_reset_threshold= 0.01

[non_local_opt]

a = 0.8085
alpha = 0.9352
c = 0.0570
gamma = 0.0152
lamda = 0.5735
beta_1 = 0.7677
beta_2 = 0.9932

maxfev = 500

global_iters = 100
method = scipy_each_step
optim_alg = COBYLA





