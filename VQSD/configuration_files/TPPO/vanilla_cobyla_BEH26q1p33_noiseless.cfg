[general]
episodes = 10000

[env]
num_qubits = 6
num_layers = 70
err_mitig = 0
rand_halt = 0

n_shots = 0
noise_models = 0
noise_values = 0

fn_type = incremental_with_fixed_ends
thresholds = [1.6e-3]
accept_err = 1.6e-3
switch_episodes = [100000]
curriculum_type = VanillaCurriculum

[problem]
ham_type = BEH2
geometry = H 0.000 0.000 -1.330; Be 0.000 0.000 0.000; H 0.000 0.000 1.330
taper = 1
mapping = jordan_wigner

[agent]
batch_size = 1000
memory_size = 20000
neurons = [1000,1000,1000,1000]
dropout = 0.
learning_rate = 0.0003
angles = 0
en_state = 1
agent_type = TPPO
agent_class = TPPO
init_net = 0

update_target_net = 500
final_gamma = 0.005
epsilon_decay = 0.99995
epsilon_min = 0.05
epsilon_restart = 1.0

[non_local_opt]

a = 0.8085
alpha = 0.9352
c = 0.0570
gamma = 0.0152
lamda = 0.5735
beta_1 = 0.7677
beta_2 = 0.9932

maxfev = 500

global_iters = 200
method = scipy_each_step
optim_alg = COBYLA





